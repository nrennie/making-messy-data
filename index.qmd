---
title: "Making 'messy' Data: An R Package for Teaching Data Wrangling with Realistic Data"
author:
  - name: Nicola Rennie
    orcid: 0000-0003-4797-557X
    email: "nrennie.research@gmail.com"
    affiliations:
      - name: Lancaster University
        department: Lancaster Medical School
        city: Lancaster
        country: UK
        postal-code: "LA1 4YW"
    attributes:
      corresponding: true
bibliography: references.bib
date: last-modified
format:
  jasa-pdf:
    keep-tex: true
  jasa-html:
    number-sections: true
execute: 
  echo: false
  eval: true
  warning: false
keywords:
  - real-world data
  - randomness
  - data issues
  - statistics
abstract: |
  Equipping students in statistics and data science with the necessary data wrangling skills to handle real-world data is a crucial aspect of their education. Real data, unlike the clean, structured examples often used in teaching, can include a variety of challenges such as typographical errors, missing values encoded in unconventional ways, unexpected spaces in text, or other inconsistencies that stem from human error or software incompatibility. These issues are common in real datasets and are essential for students to learn how to address in order to develop the practical skills needed for professional data analysis.

  However, while real data offers these valuable learning opportunities, it can also be too messy and unpredictable to be useful in a time-constrained classroom environment. Teaching with such data may overwhelm students or detract from the core statistical concepts. To address this, this paper presents an R package designed to introduce controlled levels of messiness into existing, clean teaching datasets. This package allows educators to retain the structure and simplicity of familiar teaching examples while providing students with a realistic, manageable data cleaning experience. By using this approach, instructors can implicitly teach critical data wrangling techniques, preparing students for the complexities they will encounter in real-world data analysis.
---

```{r}
#| label: setup
#| include: false
chunk_hook <- knitr::knit_hooks$get("chunk")
knitr::knit_hooks$set(chunk = function(x, options) {
  x <- chunk_hook(x, options)
  paste0("\\linespread{0.8}\n", x, "\n\n\\linespread{1.9}")
})
```

```{r}
#| label: make-example-data
#| echo: false
example_data <- tibble::tribble(
  ~month, ~x, ~y,
  "January", 2.21, 1L,
  "January", 2.29, 1L,
  "January", 1.46, 0L,
  "February", 0.55, 1L,
  "February", 0.06, 0L,
  "February", 0.03, 1L,
  "March", 0.11, 1L,
  "March", 0.13, 1L,
  "April", 0.63, 1L,
  "April", 1.39, 0L
)
```


## Introduction {#sec-intro}

Data wrangling is a fundamental skill in data analysis, yet it is often not explicitly taught as a standalone course. Instead, students are frequently expected to acquire these skills informally or are assumed to already possess them. This presents a challenge, as students may struggle with data preparation tasks that are essential for meaningful analysis. As @Hardin2015 emphasize, ‘if an analyst cannot wrangle data in a form to answer a statistical question, their utility may be limited.’ Ensuring that students develop these skills is therefore crucial for their ability to engage effectively with real-world data.

There is often a temptation when teaching statistical methods for instructors to use *nice* datasets. However, these datasets are not very realistic, and do not represent the data that students will later encounter in the real world. The gap between examples used in teaching and introductory textbooks and the real world is notably large [@Hsu2022]. Real datasets often contain issues such as typographical errors, missing values encoded in strange ways, or unexpected values. These data issues often derive from human error, poor data collection processes, or errors in pre-processing with software. Therefore, these issues are likely to arise in any analytical project, and so it is essential that students practice skills to address them.

Though some programmes may include data wrangling as a standalone course, there are many opportunities to integrate wrangling practice into other courses where students work with data. However, this can present challenges for instructors, who may not view data wrangling as part of their teaching responsibilities or may already struggle to cover core subject material within the constraints of a semester. Many available teaching datasets are already clean, and instructors often lack the time to source or modify datasets to better reflect real-world complexities. As a result, despite the importance of data wrangling skills, finding practical ways to incorporate them into existing coursework remains a significant challenge.

## Background {#sec-background}

The use of data in teaching statistics and data science has a long history, dating back to the early days of statistical education when small, manually collected datasets were used to illustrate key concepts. Classic datasets, such as the `iris` dataset have been widely used for decades. As methodology and technology evolve, it is essential that the examples used in teaching effectively prepare students for the modern world of data.

### Existing datasets for teaching

A range of teaching-specific resources exists for statistics and data science education, including domain-specific datasets and instructional tools. In the health sciences, for example, the Teaching of Statistics in the Health Sciences [CITE] resources portal provides datasets for teaching purposes, derived from real patient data. Many datasets are also available through R [@RCore] which commonly used for teaching, including `titanic`, `mtcars`, `iris`, and `palmerpenguins`. However, these datasets are often pre-cleaned or overly simplistic, making analyses too easy and limiting students’ exposure to real-world data challenges. Additionally, widely used datasets such as `iris` and `titanic` have extensive publicly available analyses, which, while helpful for learning syntax, may encourage students to rely on existing solutions rather than developing critical thinking and problem-solving skills. This issue is further amplified by the increasing use of AI-generated solutions, which allow students to bypass key aspects of data analysis. Introducing messier, more variable datasets helps ensure that students actively engage with data wrangling processes, rather than simply reproducing pre-existing approaches.

If the aim is to provide students with opportunities to learn how to work with real data, the natural suggestion may be to simply use real data when teaching. @Rivera2019 notes that when teaching using real data, "filtering, aggregating, cleaning, and other preprocessing could be needed; presenting an opportunity to introduce students to data management and data wrangling." However, using real data in teaching presents several challenges. In some cases, real datasets cannot be shared due to ethical concerns, such as those in healthcare. They may also have undergone statistical disclosure control before becoming publicly available, limiting the types of analyses that they can be used to demonstrate. Even when real data can be shared, it is often too complex or messy for instructional use. If data wrangling is not the primary learning objective, students may spend excessive time on preprocessing rather than focusing on analytical concepts. Instructors may spend time pre-cleaning data to control the level of messiness, to strike a balance between realism and usability, allowing students to develop practical skills without being overwhelmed by unnecessary complexity. However, this creates an additional, potentially time-intensive task for instructors when identifying and preparing data for teaching.

An alternative approach to obtaining data for teaching purposes is for educators to generate their own data through the use of simulation. Simulated datasets allow educators to control specific characteristics of the data, including the types of variables and how much wrangling by students would be required to make it usable for analysis. As discussed in @McSweeney2024, this approach provides flexibility in dataset design and therefore can be more pedagogically effective. However, the use of simulation to generate data requires that educators have some expertise in simulation and enough time to develop their own data-generating processes, which is often not the case. Lack of time for creating customised datasets, is a particular constraint when educators require datasets with different features for teaching different analytical methods over the course of a programme. If not performed carefully, simulated data may also be too clean and have too little noise to be realistic.

This highlights the need for an approach to obtaining data for teaching purposes that has realistic features and data issues to allow students to practice data wrangling. At the same time, this approach should be quick and easy for instructors to use for data generation, and should ensure that the resulting data is not overly complex for the teaching scenario.

### Common data issues

To best equip students with relevant data wrangling skills, it is important to identify which data issues they are most likely to encounter in the real world. As discussed in @Lewis2024, common data issues that require pre-analysis cleaning include dealing with inconsistent date formats, poor variable name choices, missing data encoded in a variety of ways, duplicated rows, variables encoded in incorrect formats, and differing formats of the same variable value.

Missing values are a common issue in data analysis. Though classes on handling and imputing missing values are not an uncommon feature of statistical modelling courses, the practice of initially identifying missing values in data is less common. In R [@RCore], missing values are explicitly represented as `NA`. In other software they may be encoded in a variety formats such as empty strings, a single space, placeholder values like 999, or other arbitrary indicators. Additionally, even within the same dataset, different columns may use different conventions for missing data. In some cases, multiple encodings may appear within a single column, each carrying distinct meanings. It is essential that students gain experience in recognising these inconsistencies, as failure to do so may result in overlooking missing values - which even the best choice of imputation method cannot overcome.

Text data, whether resulting from free-text responses or pre-defined categories, can often contain inconsistencies. This is particularly common in data originating from surveys, where open-ended questions may have been asked, or where questions and available answers have updated in different iterations of the survey. Other common sources of inconsistency in text data include variations in spacing, differences in letter case, and typographical errors. Visualisation techniques can be particularly useful for identifying these issues, as they help reveal patterns that may not be immediately apparent through visual inspection, especially when the proportion of such errors is small. However, many courses focus on teaching the use of data visualisation as a method of communicating results, and don't allow enough time for data visualisation as a means of effective data validation [@Hsu2022; @Hudiburgh2020].

## Methodology {#sec-methods}

Given the need for a more effective, realistic approach to generating data for teaching, the use of the 'messy' R package is proposed. The package takes a clean dataset and randomly introduces common data issues such as missing values, typographic errors, and inconsistencies in data representation. This approach provides students with the opportunity to practice essential data cleaning and wrangling skills, without the need for instructors to modify or replace their existing teaching examples. By adding controlled messiness to familiar datasets, the package allows students to engage with realistic data in a structured and manageable way.

The 'messy' package follows the principles of the tidyverse [@tidyverse], offering separate functions that perform specific data de-cleaning tasks, where functions names are indicative of their purpose. For example, the `add_whitespace()` function adds additional white space to character strings. As in the 'tidyverse', these separate functions can be easily piped together to create flexible and efficient combinations of tasks. Additionally, the package includes a wrapper function, `messy()`, that simplifies the process of creating messy data, allowing users to apply multiple data modifications with a single command. This design ensures that the package is intuitive and consistent, making it easy for users to integrate into their existing teaching workflows.

As with any package or function that utilises random variables, these functions require the user to set a seed to ensure their data generation is reproducible.

### Functions available

The following functions are available in the 'messy' package:

* `make_missing()`: This function randomly adds missing values into the dataset. The default is to randomly replace values with `NA`, the standard representation of missing values in R.
* `add_whitespace()`: This function randomly adds white spaces at the beginning or end of character strings. This type of error is often difficult to recognise by eye, and so this provides students with the opportunity to develop data wrangling processes for identifying unique values.
* `change_case()`: This function randomly changes the case of character strings between lowercase, uppercase, and title case. This results in small variations of the way that category values are recorded.
* `messy()`: 

### User options

The `messy()` function makes it easy to modify a dataset in one line with limited effort. However, there are several user options that can be changed to create more complex modifications:

* **Columns to adjust**: By default, missing values are added to all columns, and white spaces and case changes are made to all character or factor columns. However, users may specify a specific set of columns to modify. This also allows users to vary which functions and parameter values are applied to each column. 
* **Degree of messiness**: The default is to modify each value in a column with a probability of 10%. The can be varied to create more or less common errors.
* **Missing value representation**: The default representation of missing values is `NA`,  but users may specify a different value, or combination of values. For example, in numeric columns they may choose to use `0` or `999` alongside `NA`, and for character strings they may choose empty strings or a single space.
* **Combination of functions**: Since the functions are designed to be used in a piped workflow, it's easy for users to define and apply a custom combination of functions to a variety of columns in the data.

## Results {#sec-res}

To illustrate the way that the 'messy' package can be used to modify teaching for teaching purposes, it is applied to (i) a small, toy dataset, and (ii) the 'palmerpenguins' dataset commonly used in teaching.

### Application to a toy dataset

To illustrate the use of the `messy()` function and how its functions affect the data set, we use a small toy, example dataset as input. As seen in @tbl-show-example, the example data contains 3 columns - one character column with months of the year, one double column with numeric values, and one integer column with binary values. To allow printing of the entire output for illustrative purposes, only 10 rows are included. Since this is a toy example, not all features of the package can be exhibited in just 10 rows and 3 columns. 

```{r}
#| label: tbl-show-example
#| tbl-cap: "Initial clean data set with three columns, including character strings, numeric, and binary variables."
example_data
```

importance of setting a seed

```{r}
#| label: tbl-show-example-data
#| tbl-cap: "The result of running `messy()` function on the clean data set, which adds spaces to some of the "
#| message: false
library(messy)
set.seed(12345)
example_data |>
  messy()
```

```{r}
#| label: tbl-piping
#| tbl-cap: "The result of running custom function on the clean data set, which adds spaces to some of the "
set.seed(12345)
example_data |>
  make_missing(cols = "month", missing = " ") |>
  make_missing(cols = c("x", "y"), missing = c(NA, 999)) |>
  add_whitespace(cols = "month", messiness = 0.5)
```

### Application to {palmerpenguins}

To illustrate the use of the 'messy' package on a more realistically sized dataset, we use the 'palmerpenguins' dataset [@palmerpenguins] as an example. The 'palmerpenguins' dataset provides measurements of penguins from three species (Adélie, Chinstrap, and Gentoo) collected from three islands in the Palmer Archipelago, Antarctica. It includes variables such as species, island, bill length and depth, flipper length, body mass, and sex. The dataset is commonly used in data science education, supporting lessons in data visualisation, statistical modelling, and machine learning.

apply 

```{r}
#| label: messy-penguins
library(palmerpenguins)
set.seed(12345)
messy_penguins <- penguins |>
  make_missing(cols = "island", missing = " ") |>
  make_missing(cols = c("body_mass_g"), missing = c(999)) |>
  add_whitespace(cols = "species") |>
  change_case(cols = "species", messiness = 0.01)
```

The 'visdat' package [@visdat] is commonly used to visualise the structure of 
visualisiong missing data  commonly used , alongside naniar. These packages assume @fig-vis-missing

```{r}
#| label: fig-vis-missing
#| fig-asp: 0.7
#| fig-width: 6.5
#| fig-cap: "Visualisation of missing values in the original `palmerpenguins` data (left) and a 'messy' version of the `palmerpenguins` data (right)."
library(visdat)
library(ggplot2)
library(patchwork)
g1 <- vis_miss(penguins) +
  theme(
    text = element_text(size = 13)
  )
g2 <- vis_miss(messy_penguins) +
  theme(
    text = element_text(size = 13)
  )
g1 + g2 + plot_layout(axes = "collect") &
  theme(
    legend.position = "bottom",
    plot.margin = margin(l = 5, r = 10)
  )
```

note that the .. contains x% missing data, which is not highlighted using the default settings. students unused to ... may think they have identifed missing data, but they have not.

variable types @fig-visdat

```{r}
#| label: fig-visdat
#| fig-asp: 0.6
#| fig-width: 6.5
#| fig-cap: "Visualisation of column types in the original `palmerpenguins` data (left) and a 'messy' version of the `palmerpenguins` data (right)."
g1 <- vis_dat(penguins, sort_type = FALSE) +
  scale_fill_brewer(
    palette = "Dark2",
    na.value = "grey50",
    limits = c("character", "factor", "integer", "numeric", NA),
    drop = FALSE
  ) +
  theme(
    legend.position = "none",
    text = element_text(size = 13)
  )
g2 <- vis_dat(messy_penguins, sort_type = FALSE) +
  scale_fill_brewer(
    palette = "Dark2",
    na.value = "grey50",
    limits = c("character", "factor", "integer", "numeric", NA),
    drop = FALSE
  ) +
  theme(
    text = element_text(size = 13)
  )
g1 + g2 + plot_layout(guides = "collect", axes = "collect")
```

unique values
As seen in @fig-barchart, mimicing the use of free-text, or iterating dropdown options

```{r}
#| label: fig-barchart
#| fig-asp: 0.5
#| fig-width: 6.5
#| fig-cap: "Visualisation of unique values of the `species` column in the original `palmerpenguins` data (left) and a 'messy' version of the `palmerpenguins` data (right)."
g1 <- ggplot(
  data = penguins,
  mapping = aes(y = species)
) +
  geom_bar() +
  theme_bw(base_size = 13)
g2 <- ggplot(
  data = messy_penguins,
  mapping = aes(y = species)
) +
  geom_bar() +
  theme_bw(base_size = 13)
g1 + g2 + plot_layout(axes = "collect")
```

This provides an opportunity for students to learn essential data cleaning techniques, such as removing leading and trailing whitespace, standardising letter case, and reconciling inconsistencies in how the same values are encoded. It also gives educators the opportunity to emphasise the use of visualisation not only as a tool for data exploration but also as a crucial step in validating and identifying inconsistencies in data.

## Discussion {#sec-disc}

Although this is an R package, its usefulness extends beyond R, as datasets can be saved as CSV files for use in other programming languages. Future work may create a web application where educators can upload their own datasets, then download a 'messy' version in a variety of formats. The web application may also provide downloads of ‘messy’ versions of common datasets such as `iris` or `titanic`.

For instructors using publicly available datasets, the random nature of the output can ensures that no two datasets are identical. This may be particularly useful in the assessment setting where students receive data with the same structure but unique values—reducing the likelihood of copying and plagiarism.

The 'messy' package is also valuable outside of teaching, for developers who need datasets for testing functions or R packages, as it introduces controlled inconsistencies that help evaluate robustness.

## Supplementary {.unnumbered}

R package [@messy]

## Acknowledgments {.unnumbered}

The author is especially grateful to the R community and the wider open-source community for their positive response to the package's initial release. Special thanks go to the early users who identified bugs or suggested new features, particularly Jack Davison, Athanasia Monika Mowinckel, and Philip Leftwich.

## Declaration of interest statement {.unnumbered}

The authors report there are no competing interests to declare.

## Data availability statement {.unnumbered}

The source code for the 'messy' R package can be found on GitHub at [github.com/nrennie/messy](https://github.com/nrennie/messy). The source code and data for the examples can also be found on GitHub at [github.com/nrennie/making-messy-data](https://github.com/nrennie/making-messy-data). The `penguins` data is available through the 'palmerpenguins' R package [@palmerpenguins].

## References {.unnumbered}

::: {#refs}
:::
